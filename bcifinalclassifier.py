# -*- coding: utf-8 -*-
"""BCIfinalclassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Stiej2DNKRfIrmbic0ELROy70c6jX4Y
"""

import pandas as pd
import numpy as np
from scipy.signal import butter, lfilter
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

## load eegdata
file_path = 'BCICIV_2a_all_patients.csv'

try:
    df = pd.read_csv(file_path)
except Exception as e:
    print(f"Error loading the dataset: {e}")
    exit()

# pritn dataset to make sure in congruent
print("Dataset preview:")
print(df.head())
print()

# data preprocessing, bandpass filter
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band')
    return b, a

def bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)
    return y

# sample rate 250hz
fs = 250.0
lowcut = 0.5
highcut = 40.0

# the first three columns are not eeg data
eeg_columns = df.columns[3:]
for col in eeg_columns:
    df[col] = bandpass_filter(df[col].values, lowcut, highcut, fs)

# normalization
for col in eeg_columns:
    df[col] = (df[col] - df[col].mean()) / df[col].std()

# feature extraction
X = df.drop(columns=['label']).values  # Assuming 'label' is the column with labels
y = df['label'].values

# split in training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# make sure the shape in congruent
print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")
print()

# fisrt classifier naive bayes
clf = GaussianNB()


clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)

# evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#second classifier decision tree
clf = DecisionTreeClassifier(random_state=42)


clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)

#evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

#precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# third classifier KNN
clf = KNeighborsClassifier(n_neighbors=5)


clf.fit(X_train, y_train)

# Predict on the test set
y_pred = clf.predict(X_test)

#evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

#  precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#Fourth classifer  Randomforestclassifier

clf = RandomForestClassifier(n_estimators=100, random_state=42)

clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)

# evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#fifth classfier logistic regression
clf = LogisticRegression(max_iter=1000, random_state=42)


clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

# evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

#precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#sixth xclassifier suppport vector machine linear
clf = LinearSVC(random_state=42)

clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)

# evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

#precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#seventh classifer support vecotr machine rbf

clf = SVC(kernel='rbf', random_state=42)


clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)

# evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# precision, recall, and F1-score
print("\nClassification Report:")
print(classification_report(y_test, y_pred))